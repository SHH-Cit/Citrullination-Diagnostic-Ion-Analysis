{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyteomics import mgf, mass\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import statistics\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ion types for theoretical spectrum generation\n",
    "ion_type = ['Precur', 'y', 'b', 'a', 'INT', 'IM']\n",
    "\n",
    "# Generate each ion type\n",
    "annot_yb     = True # y-, b-, a-ion\n",
    "annot_precur = True # precursor ion\n",
    "annot_INT    = True # internal ion\n",
    "annot_IM     = True # immonium ion\n",
    "annot_dict = {\n",
    "    'Precur' : annot_precur,\n",
    "    'y'      : annot_yb,\n",
    "    'b'      : annot_yb,\n",
    "    'a'      : annot_yb,\n",
    "    'INT'    : annot_INT,\n",
    "    'IM'     : annot_IM\n",
    "}\n",
    "\n",
    "# Mass tolerance (ppm)\n",
    "ms1_ppm = 10 # MS1 level\n",
    "ms2_ppm = 15 # MS2 level\n",
    "\n",
    "# Signal-to-noise (SNR) filter for MS2 spectrum\n",
    "apply_SNR = True # Apply SNR filter\n",
    "SNR       = 2 # SNR threshold\n",
    "low       = 0.05 # Define low x% intensity as baseline noise level\n",
    "\n",
    "# Maximum charge state of sequence ions\n",
    "max_charge = 2 # 2, 3, ... 'max'\n",
    "\n",
    "# Maximum number of neutral loss from a single ion\n",
    "max_NL = 2 # 1, 2, 3...\n",
    "\n",
    "# Threshold for intensity coverage filter\n",
    "intensity_coverage = 0.2 # Filter out spectra with sum of annotated intensities < x% of sum of total intensities\n",
    "\n",
    "# Neutral loss from precursor & sequence ion\n",
    "NL_seq = {\n",
    "    'NH3' : { 'mass' : mass.calculate_mass(formula = 'NH3'),   'AA' : {'R', 'K', 'Q', 'N', 'r'} },\n",
    "    'H2O' : { 'mass' : mass.calculate_mass(formula = 'H2O'),   'AA' : {'S', 'T', 'E', 'D'} },\n",
    "    '43'  : { 'mass' : mass.calculate_mass(formula = 'HNCO'),  'AA' : {'r'} }, # Citrullination specific NL\n",
    "    '42'  : { 'mass' : mass.calculate_mass(formula = 'CN2H2'), 'AA' : {'R'} }, # Arg specific NL\n",
    "    '59'  : { 'mass' : mass.calculate_mass(formula = 'CN3H5'), 'AA' : {'R'} } # Arg specific NL\n",
    "}\n",
    "\n",
    "# Neutral loss from internal ion\n",
    "NL_INT = {\n",
    "    **NL_seq, \n",
    "    **{ 'CO' : { 'mass' : mass.calculate_mass(formula = 'CO'), 'AA' : {''} } } # CO loss from C-terminus of internal ion\n",
    "}\n",
    "\n",
    "# Common masses\n",
    "proton = mass.calculate_mass(formula = 'H')\n",
    "OH     = mass.calculate_mass(formula = 'OH')\n",
    "CO     = mass.calculate_mass(formula = 'CO')\n",
    "NH3    = mass.calculate_mass(formula = 'NH3')\n",
    "\n",
    "# Symbols for common modifications\n",
    "Mod_symbol = {\n",
    "    'C+57.021'  : 'c', # C(Carbamidomethyl) \n",
    "    'M+15.995'  : 'm', # M(Oxidation)\n",
    "    'R+0.984'   : 'r', # R(Citrullination)\n",
    "    'N+0.984'   : 'n', # N(Deamidation)\n",
    "    'Q+0.984'   : 'q', # Q(Deamidation)\n",
    "    'E-17.027'  : '@', # Pyro-Glu from Glu\n",
    "    'Q-18.011'  : '#', # Pyro-Glu from Gln    \n",
    "    'K+144.102' : 'i', # K(iTRAQ 4-plex)\n",
    "    'K+304.205' : 'u', # K(iTRAQ 8-plex)    \n",
    "    'K+229.163' : 't', # K(TMT)\n",
    "    '+144.102'  : '%', # N-term(iTRAQ 4-plex)\n",
    "    '+304.205'  : '&', # N-term(iTRAQ 8-plex)\n",
    "    '+229.163'  : '^', # N-term(TMT)\n",
    "    '+42.011'   : 'a'  # N-term(Acetyl)\n",
    "}\n",
    "\n",
    "# N-term modification symbols\n",
    "Nterm_mod_symbol = [symbol for mod, symbol in Mod_symbol.items() if len(mod.split('+')[0]) == 0]\n",
    "\n",
    "# Amino acid monoisotopic mass\n",
    "aa = {\n",
    "    'c' : 160.030649, # C(Carbamidomethyl)\n",
    "    'm' : 147.0354,   # M(Oxidation)\n",
    "    'r' : 157.085127, # R(Citrullination)\n",
    "    'n' : 115.026943, # N(Deamidation)\n",
    "    'q' : 129.042594, # Q(Deamidation)\n",
    "    '@' : 112.015593, # Pyro-Glu from Glu\n",
    "    '#' : 110.047578, # Pyro-Glu from Gln\n",
    "    'i' : 272.196963, # K(iTRAQ 4-plex)\n",
    "    'u' : 432.299963, # K(iTRAQ 8-plex)\n",
    "    't' : 357.257963, # K(TMT)\n",
    "    '%' : 144.102,    # N-term(iTRAQ 4-plex)\n",
    "    '&' : 304.205,    # N-term(iTRAQ 8-plex)\n",
    "    '^' : 229.163,    # N-term(TMT)\n",
    "    'a' : 42.011,     # N-term(Acetyl)\n",
    "    'A' : 71.037114,\n",
    "    'R' : 156.101111,\n",
    "    'N' : 114.042927,\n",
    "    'D' : 115.026943,\n",
    "    'C' : 103.009185,\n",
    "    'E' : 129.042593,\n",
    "    'Q' : 128.058578,\n",
    "    'G' : 57.021464,\n",
    "    'H' : 137.058912,\n",
    "    'I' : 113.084064,\n",
    "    'L' : 113.084064,\n",
    "    'K' : 128.094963,\n",
    "    'M' : 131.040485,\n",
    "    'F' : 147.068414,\n",
    "    'P' : 97.052764,\n",
    "    'S' : 87.032028,\n",
    "    'T' : 101.047679,\n",
    "    'W' : 186.079313,\n",
    "    'Y' : 163.06332,\n",
    "    'V' : 99.068414\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set current working directory\n",
    "PATH = \"F:/Project/\"\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files\n",
    "spec_files = glob.glob('*.mgf') # MGF file(s)\n",
    "df_UnmodR  = pd.read_csv(\"UnmodR_peptide.csv\") # UnmodR peptides w/o Cit counterpart peptides\n",
    "df_total   = pd.read_csv(\"Total_peptide.csv\") # Total identified peptides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Spectrum file (mgf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read spectrum files\n",
    "dfs = []\n",
    "for spec_file in spec_files:\n",
    "    df_temp = pd.DataFrame(mgf.read(spec_file, convert_arrays = 1, read_charges = False))\n",
    "    dfs.append(df_temp)\n",
    "\n",
    "df_exp = pd.concat(dfs).reset_index(drop = True)\n",
    "df_exp['Title'] = df_exp['params'].apply(lambda x: x.get('title')) # Get scan title\n",
    "df_exp['exp_Precursor'] = df_exp['params'].apply(lambda x: x.get('pepmass')) # Get precursor m/z\n",
    "df_exp['exp_Precursor'] = df_exp['exp_Precursor'].apply(lambda x: x[0])\n",
    "df_exp['Charge'] = df_exp['params'].apply(lambda x: x.get('charge')) # Get precursor charge state\n",
    "df_exp['Charge'] = df_exp['Charge'].apply(lambda x: x[0])\n",
    "df_exp.drop(columns = ['params'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant spectra\n",
    "df_exp.drop_duplicates('Title', keep = False, ignore_index = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retain only unassigned MS/MS spectra\n",
    "# Check whether each spectrum was identified by database searching\n",
    "df_exp['ID'] = np.where(df_exp['Title'].isin(df_total['Title']), 1, 0)\n",
    "\n",
    "# Retain only unassigned scans\n",
    "df_unID_scan = pd.DataFrame(data = df_exp.loc[df_exp['ID'] == 0])\n",
    "df_unID_scan = df_unID_scan.reset_index(drop = True)\n",
    "df_unID_scan = df_unID_scan.rename(columns = {'Title': 'unID_Title'})\n",
    "df_unID_scan = df_unID_scan.drop(['ID'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove zero intensity peaks\n",
    "nonzero_intensity = df_unID_scan['intensity array'].apply(lambda x: (x > 0).astype(int))\n",
    "df_unID_scan['intensity array'] = (df_unID_scan['intensity array']*nonzero_intensity).apply(lambda x: [i for i in x if i != 0])\n",
    "df_unID_scan['m/z array']       = (df_unID_scan['m/z array']      *nonzero_intensity).apply(lambda x: [i for i in x if i != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spectra with <20 peaks\n",
    "df_unID_scan = df_unID_scan[df_unID_scan['m/z array'].str.len() >= 20].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SNR filter\n",
    "if apply_SNR == True:\n",
    "    signal_intensity = df_unID_scan['intensity array'].apply(lambda x: \n",
    "                                                             (x > statistics.mean(sorted(x)[:round(len(x)*low)])*SNR).astype(int))\n",
    "    df_unID_scan['intensity array'] = (df_unID_scan['intensity array']*signal_intensity).apply(lambda x: [i for i in x if i != 0])\n",
    "    df_unID_scan['m/z array']       = (df_unID_scan['m/z array']      *signal_intensity).apply(lambda x: [i for i in x if i != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 UnmoR peptides to Cit peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert modifications to specific symbols\n",
    "def Mod_to_symbol(peptide):\n",
    "    for key, value in Mod_symbol.items():\n",
    "        peptide = peptide.replace(key, value)\n",
    "    return peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove N-term modification symbols\n",
    "def Nterm_mod_remove(peptide):\n",
    "    for mod in Nterm_mod_symbol:\n",
    "        peptide = peptide.replace(mod, '')\n",
    "    return peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert modifications to specific symbols\n",
    "df_UnmodR['mod_Peptide'] = df_UnmodR['Peptide'].apply(lambda x: Mod_to_symbol(x)) # Convert modification to specific symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only unique UnmodR peptides\n",
    "df_UnmodR_pep = pd.DataFrame(df_UnmodR['mod_Peptide'])\n",
    "df_UnmodR_pep = df_UnmodR_pep.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Remove peptides without Arg\n",
    "df_UnmodR_pep = df_UnmodR_pep[df_UnmodR_pep.mod_Peptide.str.contains(\"R\")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of Arg\n",
    "df_UnmodR_pep['Arg_Count'] = df_UnmodR_pep['mod_Peptide'].str.count(\"R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort with respect to the No. of Arg\n",
    "df_UnmodR_pep = df_UnmodR_pep.sort_values('Arg_Count', ascending = True).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for finding Arg position(s) on the peptide sequence\n",
    "def Arg_position(sequence):    \n",
    "    sequence = list(sequence)\n",
    "    Arg_index = [pos + 1 for pos, AA in enumerate(sequence) if AA == 'R']\n",
    "    \n",
    "    return Arg_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Arg position(s) on peptide sequences\n",
    "df_UnmodR_pep['Arg_position'] = df_UnmodR_pep['mod_Peptide'].apply(lambda x: Arg_position(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for generating counterpart Cit peptide(s)\n",
    "def Cit_counterpart(sequence, Arg_pos):\n",
    "    appended_list = []\n",
    "    for pos in Arg_pos:\n",
    "        seq_list = list(sequence)\n",
    "        seq_list[pos - 1] = 'r'\n",
    "        seq_list = \"\".join(seq_list)\n",
    "        appended_list.append(seq_list)\n",
    "        \n",
    "    return appended_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counterpart Cit peptide(s)\n",
    "df_UnmodR_pep['Cit_peptide'] = df_UnmodR_pep.apply(lambda x: Cit_counterpart(x['mod_Peptide'], x['Arg_position']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for calculating all possible charge states of Cit peptide\n",
    "def charge_state(sequence):    \n",
    "    Basic_AA = [AA for AA in sequence[0] if AA == 'R' or AA == 'K' or AA == 'H']\n",
    "    max_charge = len(Basic_AA) + 1  \n",
    "    charge_state = [c for c in range(1, max_charge + 1)]\n",
    "\n",
    "    return charge_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column for possible charge states of Cit peptide\n",
    "df_UnmodR_pep['Cit_Charge'] = df_UnmodR_pep['Cit_peptide'].apply(lambda x: charge_state(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Cit dataframe\n",
    "df_pep = df_UnmodR_pep[['Cit_peptide', 'Cit_Charge']]\n",
    "df_pep = df_pep.rename(columns = {'Cit_peptide': 'mod_Peptide', 'Cit_Charge': 'Charge'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand all Cit peptides\n",
    "df_pep = df_pep.explode('mod_Peptide').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand all Cit charge states\n",
    "df_pep = df_pep.explode('Charge').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Cit peptide length\n",
    "df_pep['Pep_length'] = df_pep['mod_Peptide'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get theoretical precursor m/z\n",
    "df_pep['mz_Precursor'] = ([sum(aa.get(x, 0) for x in ','.join(j)) + OH + proton \n",
    "                           for j in df_pep['mod_Peptide'].astype(str).fillna('')] + df_pep['Charge']*proton)/df_pep['Charge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of Cit\n",
    "df_pep['Cit_Count'] = df_pep['mod_Peptide'].str.count(\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove N-term modification symbols\n",
    "df_pep.insert(loc = 1, column = 'seq_Peptide', value = df_pep['mod_Peptide'].apply(lambda x: Nterm_mod_remove(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert modification symbols to original delta masses\n",
    "def Symbol_to_mod(peptide):\n",
    "    for key, value in Mod_symbol.items():\n",
    "        peptide = peptide.replace(value, key)\n",
    "    return peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original peptide sequence \n",
    "df_pep.insert(loc = 0, column = 'Peptide', value = df_pep['mod_Peptide'].apply(lambda x: Symbol_to_mod(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Theoretical spectrum generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Ion sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to generate ion sequence\n",
    "def getCombinations_seq (lst): # Sequence ion\n",
    "    for i, j in itertools.combinations(range(len(lst) + 1), 2):\n",
    "        yield lst[0:j]\n",
    "\n",
    "def getCombinations_INT (lst): # Internal ion\n",
    "    for i, j in itertools.combinations(range(len(lst) + 1), 2):\n",
    "        yield lst[i:j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get ion sequence\n",
    "# Sequence ion\n",
    "df_pep_mz = df_pep.copy()\n",
    "\n",
    "if annot_yb == True:\n",
    "    # y ion\n",
    "    Cterm_combo = df_pep['seq_Peptide'].str[1:].apply(lambda x: [i for i in sorted(list(set(sorted(getCombinations_seq (x[::-1]), key = len))))])\n",
    "    df_pep_mz   = pd.concat([df_pep_mz, \n",
    "                             pd.DataFrame(Cterm_combo.values.tolist(), \n",
    "                                          columns = ['seq_y_' + str(i) for i in range(1, len(max(Cterm_combo, key = len)) + 1)])], axis=1)\n",
    "    # b ion\n",
    "    Nterm_mod = df_pep['mod_Peptide'].apply(lambda x: ''.join([AA for AA in x if AA in Nterm_mod_symbol]))\n",
    "    Nterm_combo = df_pep['seq_Peptide'].str[0:-1].apply(lambda x: [i for i in sorted(list(set(sorted(getCombinations_seq (x), key = len))))])\n",
    "    Nterm_combo_mod = pd.concat([Nterm_mod, Nterm_combo], axis = 1).apply(lambda x: \n",
    "                                                                          [x['mod_Peptide'] + ion for ion in x['seq_Peptide']], axis = 1)\n",
    "    df_pep_mz   = pd.concat([df_pep_mz, \n",
    "                             pd.DataFrame(Nterm_combo_mod.values.tolist(), \n",
    "                                          columns = ['seq_b_' + str(i) for i in range(1, len(max(Nterm_combo_mod, key = len)) + 1)])], axis=1)\n",
    "    # a ion\n",
    "    df_pep_mz   = pd.concat([df_pep_mz, \n",
    "                             pd.DataFrame(Nterm_combo_mod.values.tolist(), \n",
    "                                          columns = ['seq_a_' + str(i) for i in range(1, len(max(Nterm_combo_mod, key = len)) + 1)])], axis=1)\n",
    "\n",
    "# Internal ion\n",
    "if annot_INT == True:\n",
    "    INT_combo   = df_pep['seq_Peptide'].str[1:-1].apply(lambda x: [i for i in sorted(getCombinations_INT(x), key = len) if len(i) > 1])\n",
    "    df_pep_mz   = pd.concat([df_pep_mz, \n",
    "                             pd.DataFrame(INT_combo.values.tolist(), \n",
    "                                          columns = ['seq_INT_' + str(i) for i in range(1, len(max(INT_combo, key = len)) + 1)])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get ion annotation\n",
    "# Sequence ion\n",
    "df_pep_label = df_pep.copy()\n",
    "\n",
    "if annot_yb == True:\n",
    "    # y ion\n",
    "    Cterm_combo_label = Cterm_combo.apply(lambda x: ['y' + str(len(i)) for i in x])\n",
    "    df_pep_label = pd.concat([df_pep_label, \n",
    "                              pd.DataFrame(Cterm_combo_label.values.tolist(), \n",
    "                                           columns = ['seq_y_' + str(i) for i in range(1, len(max(Cterm_combo, key = len)) + 1)])], axis=1)\n",
    "    # b ion\n",
    "    Nterm_combo_label = Nterm_combo.apply(lambda x: ['b' + str(len(i)) for i in x])\n",
    "    df_pep_label = pd.concat([df_pep_label, \n",
    "                              pd.DataFrame(Nterm_combo_label.values.tolist(), \n",
    "                                           columns = ['seq_b_' + str(i) for i in range(1, len(max(Nterm_combo, key = len)) + 1)])], axis=1)\n",
    "    # a ion\n",
    "    Nterm_combo_label = Nterm_combo.apply(lambda x: ['a' + str(len(i)) for i in x])\n",
    "    df_pep_label = pd.concat([df_pep_label, \n",
    "                              pd.DataFrame(Nterm_combo_label.values.tolist(), \n",
    "                                           columns = ['seq_a_' + str(i) for i in range(1, len(max(Nterm_combo, key = len)) + 1)])], axis=1)\n",
    "\n",
    "# Internal ion\n",
    "if annot_INT == True:\n",
    "    df_pep_label = pd.concat([df_pep_label, \n",
    "                              pd.DataFrame(INT_combo.values.tolist(), \n",
    "                                           columns = ['seq_INT_' + str(i) for i in range(1, len(max(INT_combo, key=len)) + 1)])], axis=1)\n",
    "\n",
    "# Precursor ion\n",
    "if annot_precur == True:\n",
    "    df_pep_label.loc[(df_pep_label.mz_Precursor != np.nan), 'mz_Precursor'] = 'Precursor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Singly charged ion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to calculate m/z for each ion type\n",
    "def y_mz(x): # y-ion\n",
    "    return sum(aa.get(a, 0) for a in ','.join(x)) + 2*(proton) + OH \n",
    "\n",
    "def b_mz(x): # b-ion\n",
    "    return sum(aa.get(a, 0) for a in ','.join(x)) + proton\n",
    "\n",
    "def a_mz(x): # a-ion\n",
    "    return sum(aa.get(a, 0) for a in ','.join(x)) + proton - CO\n",
    "\n",
    "def INT_mz(x): # internal ion\n",
    "    return sum(aa.get(a, 0) for a in ','.join(x)) + proton\n",
    "\n",
    "mz_dict = {\n",
    "    'y'   : y_mz,\n",
    "    'b'   : b_mz,\n",
    "    'a'   : a_mz,\n",
    "    'INT' : INT_mz\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate m/z for each ion type\n",
    "for ion in ion_type:\n",
    "    if ion in ['y', 'b', 'a', 'INT'] and annot_dict.get(ion) == True:\n",
    "        df_temp = df_pep_mz.filter(like = 'seq_%s' % (ion)).apply(lambda x: [mz_dict.get(ion)(i) if pd.notnull(i) else np.nan for i in x])\n",
    "        df_temp.rename(columns = lambda x: x.replace('seq', 'mz'), inplace = True)\n",
    "        df_pep_mz = pd.concat([df_pep_mz, df_temp], axis = 1)\n",
    "\n",
    "# Update annotation dataframe\n",
    "df_label_temp = df_pep_label.filter(like='seq').drop(columns = 'seq_Peptide')\n",
    "df_label_temp.rename(columns = lambda x: x.replace('seq', 'mz'), inplace = True)\n",
    "df_pep_label = pd.concat([df_pep_label, df_label_temp], axis = 1)\n",
    "df_pep_label.fillna(value = np.nan, inplace = True)\n",
    "\n",
    "# Replace None to NaN\n",
    "df_pep_mz.fillna(value = np.nan, inplace = True)\n",
    "df_pep_label.fillna(value = np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty columns\n",
    "df_pep_mz    = df_pep_mz.dropna(how = 'all', axis = 1)\n",
    "df_pep_label = df_pep_label.dropna(how = 'all', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Neutral loss variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for generating NL combinations\n",
    "def NL_combo(x, max_NL):    \n",
    "    \n",
    "    NL_label = [] # NL combinations\n",
    "    for i in range(1, max_NL + 1):\n",
    "        temp = list(itertools.product(list(x.keys()),repeat = i))\n",
    "        NL_label.append(temp)\n",
    "        \n",
    "    NL_label = list(itertools.chain.from_iterable(NL_label))\n",
    "    NL_label = [tuple(sorted(tuple_)) for tuple_ in NL_label]\n",
    "    myset = set(NL_label)\n",
    "    NL_label = sorted(myset)\n",
    "    for i in range(len(NL_label)):\n",
    "        NL_label[i] = '-'.join(NL_label[i])    \n",
    "        \n",
    "    NL_mz = [sub.split('-') for sub in NL_label] # NL combinations m/z\n",
    "    for i in range(len(NL_mz)):\n",
    "        NL_mz[i] = sum(x.get(NL_mz[i][j])['mass'] for j in range(len(NL_mz[i]))) \n",
    "        \n",
    "    return NL_label, NL_mz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for checking whether NL condition is met for each ion\n",
    "def NL_condition(NL_AA_list, sequence):    \n",
    "    \n",
    "    c = Counter(sequence)\n",
    "    \n",
    "    # If one-to-one NL type exists, take care of it first\n",
    "    for NL_group in NL_AA_list:\n",
    "        if len(NL_group) == 1:\n",
    "            if NL_group[0] not in sequence:\n",
    "                return\n",
    "            else:\n",
    "                if len(NL_AA_list) > 1:\n",
    "                    if c[NL_group[0]] >= 1:\n",
    "                        c[NL_group[0]] -= 1\n",
    "                    elif c[NL_group[0]] <= 0:\n",
    "                        return\n",
    "                elif len(NL_AA_list) == 1:\n",
    "                    return True\n",
    "    \n",
    "    # Check if remaining NL types is feasible in each ion\n",
    "    NL_AA_list = [NL_group for NL_group in NL_AA_list if len(NL_group) > 1]\n",
    "    common_AA  = list(set(itertools.chain.from_iterable(NL_AA_list)))\n",
    "    \n",
    "    # If there are only one-to-one NL types, return True\n",
    "    if len(NL_AA_list) == 0:\n",
    "        return True\n",
    "    \n",
    "    # In case of one-to-multiple NL types\n",
    "    for AA in list(c):\n",
    "        if AA not in common_AA:\n",
    "            del c[AA]\n",
    "        \n",
    "    if sum(c.values()) >= len(NL_AA_list):\n",
    "        return True   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create NL variant dataframes\n",
    "df_pep_mz_temp    = df_pep_mz.copy()\n",
    "df_pep_label_temp = df_pep_label.copy()\n",
    "\n",
    "for ion in ['Precur', 'y', 'b', 'a', 'INT']:\n",
    "    if annot_dict.get(ion) == True:\n",
    "        NL_list = []\n",
    "        if ion == 'Precur':\n",
    "            NL_list  = NL_combo(NL_seq, max_NL)\n",
    "            df_seq   = df_pep_mz_temp[['seq_Peptide']]\n",
    "            df_mz    = df_pep_mz_temp[['mz_Precursor']]\n",
    "            df_label = df_pep_label_temp[['mz_Precursor']]\n",
    "        elif ion in ['y', 'b', 'a']:\n",
    "            NL_list     = NL_combo(NL_seq, max_NL)\n",
    "            df_seq      = df_pep_mz_temp[[col for col in df_pep_mz_temp.columns if 'seq_%s' %(ion) in col]]\n",
    "            df_seq_temp = pd.Series(df_seq.values.tolist()).apply(lambda x: [i for i in x if isinstance(i, str)])\n",
    "            df_mz       = df_pep_mz_temp[[col for col in df_pep_mz_temp.columns if 'mz_%s'  %(ion) in col]]\n",
    "            df_label    = df_pep_label_temp[[col for col in df_pep_label_temp.columns if 'mz_%s' %(ion) in col]]       \n",
    "        elif ion == 'INT':\n",
    "            NL_list     = NL_combo(NL_INT, max_NL)\n",
    "            df_seq      = df_pep_mz_temp[[col for col in df_pep_mz_temp.columns if 'seq_%s' %(ion) in col]]\n",
    "            df_seq_temp = pd.Series(df_seq.values.tolist()).apply(lambda x: [i for i in x if isinstance(i, str)])\n",
    "            df_mz       = df_pep_mz_temp[[col for col in df_pep_mz_temp.columns if 'mz_%s'  %(ion) in col]]\n",
    "            df_label    = df_pep_label_temp[[col for col in df_pep_mz_temp.columns if 'mz_%s' %(ion) in col]]\n",
    "\n",
    "        # For each NL type get NL variant m/z\n",
    "        if NL_list != []: # If the ion types are to be included\n",
    "            for NL in NL_list[0]:\n",
    "                NL_AA_list = []\n",
    "                for sub_NL in NL.split('-'):\n",
    "\n",
    "                    if ion in ['Precur', 'y', 'b', 'a']:\n",
    "                        temp = list(NL_seq.get(sub_NL)['AA'])\n",
    "                    elif ion == 'INT':\n",
    "                        temp = list(NL_INT.get(sub_NL)['AA'])\n",
    "                    NL_AA_list.append(temp)\n",
    "                \n",
    "                # m/z dataframe\n",
    "                if ion == 'Precur':\n",
    "                    df_bool     = df_seq.applymap(lambda x: 1 if NL_condition(NL_AA_list, str(x)) == True else np.nan)\n",
    "                    df_mz_temp  = pd.DataFrame(df_bool.values*df_mz.values, columns = df_mz.columns, index = df_mz.index)\n",
    "                    df_mz_temp  = df_mz_temp.replace({0:np.nan})\n",
    "                    df_mz_temp['mz_Precursor'] = df_mz_temp.mz_Precursor*df_pep_mz_temp.Charge # Convert m/z to mass\n",
    "                    df_mz_temp  = df_mz_temp.apply(lambda x: 0 if str(x) == np.nan else x - NL_list[1][NL_list[0].index(NL)])\n",
    "                    df_mz_temp['mz_Precursor'] = df_mz_temp.mz_Precursor/df_pep_mz_temp.Charge # Convert mass to m/z\n",
    "                    df_mz_temp.rename(columns = lambda x: x + '-%s' % (NL), inplace = True)\n",
    "                    df_pep_mz_temp = pd.concat([df_pep_mz_temp, df_mz_temp], axis = 1)                \n",
    "                else:\n",
    "                    df_bool     = pd.DataFrame(df_seq_temp.apply(lambda x: [1 if NL_condition(NL_AA_list, i) == True \n",
    "                                                                            else np.nan for i in x]).tolist())\n",
    "                    df_mz_temp  = pd.DataFrame(df_bool.values*df_mz.values, columns = df_mz.columns, index = df_mz.index)\n",
    "                    NL_mz       = NL_list[1][NL_list[0].index(NL)]\n",
    "                    df_mz_temp  = df_mz_temp - NL_mz\n",
    "                    df_mz_temp.rename(columns = lambda x: x + '-%s' % (NL), inplace = True)\n",
    "                    df_pep_mz_temp = pd.concat([df_pep_mz_temp, df_mz_temp], axis = 1)\n",
    "\n",
    "                # Annotation dataframe\n",
    "                df_label_temp = (df_bool==1).astype(int) * df_label.values\n",
    "                df_label_temp = df_label_temp.replace(r'^\\s*$', np.nan, regex=True)\n",
    "                df_label_temp.columns = df_label.columns\n",
    "                df_label_temp = pd.DataFrame(np.where(df_label_temp.notnull(), df_label_temp.astype(str) + '-' + NL, np.nan), \n",
    "                                             columns = df_label_temp.columns)\n",
    "                df_label_temp.rename(columns = lambda x: x + '-%s' % (NL), inplace = True)\n",
    "                df_pep_label_temp = pd.concat([df_pep_label_temp, df_label_temp], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy temporary dataframe back into original dataframe\n",
    "df_pep_mz    = df_pep_mz_temp.copy()\n",
    "df_pep_label = df_pep_label_temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty columns\n",
    "df_pep_mz    = df_pep_mz.dropna(how = 'all', axis = 1)\n",
    "df_pep_label = df_pep_label.dropna(how = 'all', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Multiply charged ion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for checking whether multiple charge state condition is met for each ion\n",
    "def multi_charge_condition(charge, sequence):\n",
    "    \n",
    "    if pd.notnull(sequence):\n",
    "        # Count the number of basic residues\n",
    "        AA_count = sequence.count('R') + sequence.count('K') + sequence.count('H')\n",
    "\n",
    "        # Condition for multiple charge state\n",
    "        if AA_count + 1 >= charge:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create multiple charge state dataframe\n",
    "if max_charge > 1:\n",
    "    # Create temporary m/z and annotation dataframe\n",
    "    df_seq   = df_pep_mz[[col for col in df_pep_mz.columns       \n",
    "                          if any(['seq_y' in col, 'seq_b' in col, 'seq_a' in col]) == True]]\n",
    "    df_mz    = df_pep_mz[[col for col in df_pep_mz.columns       \n",
    "                          if any(['mz_y' in col, 'mz_b' in col, 'mz_a' in col]) == True]]\n",
    "    df_label = df_pep_label[[col for col in df_pep_label.columns \n",
    "                          if any(['mz_y' in col, 'mz_b' in col, 'mz_a' in col]) == True]]\n",
    "    df_pep_mz_temp    = df_pep_mz.copy()\n",
    "    df_pep_label_temp = df_pep_label.copy()\n",
    "\n",
    "    # For each charge state get m/z\n",
    "    if max_charge == 'max':\n",
    "        charge_boundary = df_pep_mz['Charge'].max()\n",
    "    else:\n",
    "        charge_boundary = max_charge\n",
    "\n",
    "    for charge in range(2, charge_boundary + 1): # Generate multiply charged sequence ions (from +2 to predefined max. charge)\n",
    "        # m/z dataframe\n",
    "        df_charge = df_pep_mz['Charge'].copy()\n",
    "        df_charge.loc[df_charge < charge] = 0\n",
    "        df_bool1  = df_seq.apply(lambda x: [multi_charge_condition(charge, ion) if isinstance(ion, str) else 0 for ion in x])\n",
    "        df_bool1  = pd.concat([df_charge, df_bool1], axis = 1)\n",
    "        df_bool1.loc[df_bool1['Charge'] == 0, df_bool1.columns] = 0\n",
    "        df_bool1  = df_bool1.drop(columns = 'Charge')\n",
    "\n",
    "        df_mz_temp  = df_mz.copy()\n",
    "        for column in df_mz_temp.columns:\n",
    "            df_mz_temp[column] = df_bool1['%s' % (column.split('-')[0].replace('mz', 'seq'))]\n",
    "        df_mz_temp  = df_mz_temp.replace({0:np.nan})\n",
    "        df_mz_temp  = pd.DataFrame(df_mz_temp.values*df_mz.values, columns = df_mz_temp.columns, index = df_mz_temp.index)\n",
    "        df_mz_temp  = (df_mz_temp + proton*(charge - 1))/charge\n",
    "        df_mz_temp.rename(columns = lambda x: x + '%s' % (\"+\"*charge ), inplace = True)\n",
    "        df_pep_mz_temp = pd.concat([df_pep_mz_temp, df_mz_temp], axis = 1)\n",
    "\n",
    "        # Annotation dataframe\n",
    "        df_bool2      = df_mz_temp.notnull().astype(int)  \n",
    "        df_label_temp = pd.DataFrame(df_bool2.values*df_label.values,\n",
    "                                     columns = df_label.columns, index = df_label.index)\n",
    "        df_label_temp = df_label_temp.replace(r'^\\s*$', np.nan, regex=True)\n",
    "        df_label_temp = df_label_temp.replace({0:np.nan})\n",
    "        df_label_temp = pd.DataFrame(np.where(df_label_temp.notnull(), df_label_temp.astype(str) + '+'*charge, np.nan), \n",
    "                                     columns = df_label_temp.columns)\n",
    "        df_label_temp.columns = df_label_temp.columns + '+'*charge\n",
    "        df_pep_label_temp = pd.concat([df_pep_label_temp, df_label_temp], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy temporary dataframe back into original dataframe\n",
    "df_pep_mz    = df_pep_mz_temp.copy()\n",
    "df_pep_label = df_pep_label_temp.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Immonium ion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Immonium ions (IM, IM-NH3)\n",
    "if annot_IM == True:\n",
    "    # m/z dataframe\n",
    "    df_IM_mz             = pd.DataFrame([[aa.get(AA) + proton - CO for AA in seq] for seq in df_pep_mz.seq_Peptide.tolist()])\n",
    "    df_IM_mz.columns     = ['mz_IM_%s' % (n+1) for n in range(df_pep_mz['Pep_length'].max())]    \n",
    "    df_IM_NH3_mz         = df_IM_mz - NH3\n",
    "    df_IM_NH3_mz.columns = [col.replace('IM', 'IM-NH3') for col in df_IM_mz.columns]\n",
    "    df_pep_mz            = df_pep_mz.join([df_IM_mz, df_IM_NH3_mz])\n",
    "\n",
    "    # Annotation dataframe\n",
    "    df_IM_label             = pd.DataFrame([['IM(%s)' % (AA) for AA in seq] for seq in df_pep_label.seq_Peptide.tolist()])\n",
    "    df_IM_label.columns     = ['mz_IM_%s' % (n+1) for n in range( df_pep_label['Pep_length'].max())]   \n",
    "    df_IM_NH3_label         = pd.DataFrame(np.where((df_IM_label.notnull()), df_IM_label.astype(str) + '-NH3', np.nan))\n",
    "    df_IM_NH3_label.columns = [col.replace('IM', 'IM-NH3') for col in df_IM_label.columns]\n",
    "    df_pep_label            = df_pep_label.join([df_IM_label, df_IM_NH3_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty columns\n",
    "df_pep_mz    = df_pep_mz.dropna(how = 'all', axis = 1)\n",
    "df_pep_label = df_pep_label.dropna(how = 'all', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Match precursor m/z & charge between experimental & theoretical spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframes based on precursor m/z\n",
    "new_row_index = list(df_pep_mz.sort_values('mz_Precursor', ascending = True).index)\n",
    "df_pep_mz.sort_values('mz_Precursor', ascending = True, ignore_index = True, inplace = True)\n",
    "df_pep_label  = df_pep_label.reindex(new_row_index).reset_index(drop = True)\n",
    "df_unID_scan.sort_values('exp_Precursor', ascending = True, ignore_index = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get precursor m/z of theoretical and unassigned spectra\n",
    "mz_theo = pd.DataFrame(df_pep_mz['mz_Precursor'])\n",
    "mz_unID = pd.DataFrame(df_unID_scan['exp_Precursor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check whether precursor m/z matches between theoretical and unassigned spectra\n",
    "# Split unassigned dataframe into smaller chunks\n",
    "chunk = 10\n",
    "mz_unID_chunk       = np.array_split(mz_unID, chunk)\n",
    "appended_unID       = pd.DataFrame()\n",
    "appended_theo       = pd.DataFrame()\n",
    "appended_unID_order = pd.DataFrame()\n",
    "\n",
    "for i in range(0, chunk):\n",
    "    \n",
    "    # Get theoretical precursor m/z in unassigned chunk m/z range\n",
    "    mz_theo_slice = mz_theo[mz_theo['mz_Precursor'].between(mz_unID_chunk[i].iloc[0][0], mz_unID_chunk[i].iloc[-1][0])]\n",
    "    \n",
    "    # Get nominal m/z\n",
    "    theo_array     = np.array(mz_theo_slice)\n",
    "    unID_array     = np.array(mz_unID_chunk[i])\n",
    "    theo_array_int = theo_array.astype(int)\n",
    "    unID_array_int = unID_array.astype(int)\n",
    "    \n",
    "    # Check for matching nominal m/z\n",
    "    theo_array_overlap  = np.in1d(theo_array_int, unID_array_int).reshape(len(theo_array_int), 1)*theo_array\n",
    "    theo_array          = theo_array_overlap[theo_array_overlap > 0] # Retain only nominal m/z-matched m/z\n",
    "    unID_array_overlap  = np.in1d(unID_array_int, theo_array_int).reshape(len(unID_array_int), 1)*unID_array\n",
    "    unID_array          = unID_array_overlap[unID_array_overlap > 0] # Retain only nominal m/z-matched m/z\n",
    "    unID_order          = (unID_array_overlap > 0).astype(int) # Keep original unassigned array order\n",
    "    theo_order          = (theo_array_overlap > 0).astype(int)  # Keep original theoretical array order\n",
    "    appended_unID_order = pd.concat([appended_unID_order, pd.DataFrame(unID_order)], axis = 0)\n",
    "    \n",
    "    # Match precursor m/z\n",
    "    array_mz_theo   = np.tile(theo_array.reshape(len(theo_array), 1), (1, unID_array.shape[0]))\n",
    "    array_mz_unID   = np.transpose(np.tile(unID_array.reshape(len(unID_array), 1), (1, theo_array.shape[0])))\n",
    "    array_mz_eCheck = abs(array_mz_theo - array_mz_unID) < (array_mz_theo*ms1_ppm*1e-6)\n",
    "    array_match     = 1*(array_mz_eCheck.sum(axis = 0) > 0)\n",
    "    appended_unID   = pd.concat([appended_unID, pd.DataFrame(array_match)], axis = 0)\n",
    "\n",
    "    # Attach matched theoretical spectra indices\n",
    "    df_theo_order       = pd.DataFrame(theo_order)\n",
    "    df_theo_order.index = mz_theo_slice.index\n",
    "    df_check            = pd.DataFrame(array_mz_eCheck)\n",
    "    theo_match_index    = df_theo_order.index[df_theo_order[0] != 0].tolist()\n",
    "    df_check.index      = theo_match_index\n",
    "    empty_df            = pd.DataFrame(index = df_theo_order.index, columns = [0])\n",
    "    df_check            = empty_df.combine_first(df_check)\n",
    "    \n",
    "    appended_theo_temp  = []\n",
    "    for col in df_check.columns:\n",
    "        list_temp = df_check.index[df_check[col] == True].tolist()\n",
    "        appended_theo_temp.append(list_temp)\n",
    "    appended_theo = pd.concat([appended_theo, pd.DataFrame(appended_theo_temp)], axis = 0)\n",
    "    print('Matching precursor m/z btw theoretical & unassigned spectra: ' + str(i) + str('/%s chunks processed') %(chunk), end=\"\\r\")\n",
    "\n",
    "appended_unID       = appended_unID.reset_index(drop = True)\n",
    "appended_theo       = appended_theo.reset_index(drop = True)\n",
    "appended_unID_order = appended_unID_order.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reshape to original dataframe shape\n",
    "unID_match_index    = appended_unID_order.index[appended_unID_order[0] != 0].tolist() # Get matched row indices\n",
    "appended_unID.index = unID_match_index # Match with original row index\n",
    "appended_theo.index = unID_match_index # Match with original row index\n",
    "empty_df            = pd.DataFrame(index = appended_unID_order.index, columns = [0])\n",
    "appended_unID_match = empty_df.combine_first(appended_unID) # Reshape to original row length\n",
    "appended_theo_match = empty_df.combine_first(appended_theo) # Reshape to original row length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with experimental dataframe\n",
    "df_unID_scan['mz_Check']              = appended_unID_match\n",
    "df_unID_scan['matched_theo_spectrum'] = appended_theo_match.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered experimental dataframe\n",
    "df_unID_scan_filter_mz = df_unID_scan.loc[df_unID_scan['mz_Check'] == 1].reset_index(drop = True) # Retain only precursor m/z matched spectra\n",
    "df_unID_scan_filter_mz['matched_theo_spectrum'] = df_unID_scan_filter_mz['matched_theo_spectrum'].apply(lambda x: [int(index) for index in x if pd.notnull(index)])\n",
    "df_unID_scan_filter_mz = df_unID_scan_filter_mz.explode('matched_theo_spectrum').reset_index(drop = True) # Expand all rows with multiple matching theo spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for charge match\n",
    "charge_theo = pd.DataFrame(df_pep_mz['Charge']).rename(columns = {'Charge': 'Charge_theo'})\n",
    "charge_theo['matched_theo_spectrum'] = charge_theo.index\n",
    "df_unID_scan_filter_mz = df_unID_scan_filter_mz.merge(charge_theo, on = 'matched_theo_spectrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a m/z-charge filtered unassigned dataframe\n",
    "df_unID_scan_filter_mz['Charge_Check'] = df_unID_scan_filter_mz[['Charge', 'Charge_theo']].apply(lambda x: \n",
    "                                                                                                 1 if x['Charge'] == x['Charge_theo'] \n",
    "                                                                                                 else 0, axis = 1)\n",
    "df_unID_scan_filter_mz_charge = df_unID_scan_filter_mz[df_unID_scan_filter_mz['Charge_Check'] == 1].reset_index(drop = True)\n",
    "df_unID_scan_filter_mz_charge.drop(columns = ['mz_Check', 'Charge_theo', 'Charge_Check'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Retain only theoretical spectra with precursor m/z & charge matched to those of unassigned spectra\n",
    "# m/z dataframe\n",
    "df_pep_mz_filter = df_pep_mz.loc[list(set([i for i in df_unID_scan_filter_mz_charge['matched_theo_spectrum'].tolist()]))]\n",
    "df_pep_mz_filter.insert(loc = 0, column = 'matched_theo_spectrum', value = df_pep_mz_filter.index)\n",
    "df_pep_mz_filter = df_pep_mz_filter.reset_index(drop = True)\n",
    "df_pep_mz_filter.drop(columns = ['mz_Precursor', 'Charge'], inplace = True)\n",
    "\n",
    "# Annotation dataframe\n",
    "df_pep_label_filter = df_pep_label.loc[list(set([i for i in df_unID_scan_filter_mz_charge['matched_theo_spectrum'].tolist()]))]\n",
    "df_pep_label_filter.insert(loc = 0, column = 'matched_theo_spectrum', value = df_pep_label_filter.index)\n",
    "df_pep_label_filter = df_pep_label_filter.reset_index(drop = True)\n",
    "df_pep_label_filter.drop(columns = ['mz_Precursor', 'Charge'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. XCorr score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get binned spectrum\n",
    "def bin_spec(mz_array, intensity_array):\n",
    "    # Set first & end mass for binning MS2 spectra\n",
    "    first_mass = 140\n",
    "    end_mass   = 1000\n",
    "    fragment_bin_tol = 0.01 # Set fragment bin tolerance (Da)\n",
    "    bin_size         = int((end_mass - first_mass)/fragment_bin_tol) # Set bin size\n",
    "    \n",
    "    binned_spectrum = stats.binned_statistic(mz_array, intensity_array, \n",
    "                                             statistic = 'max', bins = bin_size, range = (first_mass, end_mass))[0]\n",
    "    \n",
    "    return binned_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get binned theoretical spectrum\n",
    "def bin_theo_spec(mz_array):\n",
    "    # Set first & end mass for binning MS2 spectra\n",
    "    first_mass = 140\n",
    "    end_mass   = 1000\n",
    "    fragment_bin_tol = 0.01 # Set fragment bin tolerance (Da)\n",
    "    bin_size         = int((end_mass - first_mass)/fragment_bin_tol) # Set bin size\n",
    "    \n",
    "    # Set all intensities of theroetical peaks to 1\n",
    "    intensity_array = np.empty(len(mz_array))\n",
    "    intensity_array.fill(1)\n",
    "    \n",
    "    binned_spectrum = stats.binned_statistic(mz_array, intensity_array, \n",
    "                                             statistic = 'max', bins = bin_size, range = (first_mass, end_mass))[0]\n",
    "    \n",
    "    return binned_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by matched spectrum index\n",
    "df_unID_scan_filter_mz_charge.sort_values('matched_theo_spectrum', ignore_index = True, inplace = True)\n",
    "df_pep_mz_filter.sort_values('matched_theo_spectrum', ignore_index = True, inplace = True)\n",
    "df_pep_label_filter.sort_values('matched_theo_spectrum', ignore_index = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a m/z array column to theoretical dataframe\n",
    "df_pep_mz_filter['m/z array'] = df_pep_mz_filter.filter(like = 'mz').values.tolist()\n",
    "df_pep_mz_filter['m/z array'] = df_pep_mz_filter['m/z array'].apply(lambda x: [mz for mz in x if pd.notnull(mz)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split unassigned dataframe into smaller chuncks\n",
    "unID_match_index    = list(set(df_unID_scan_filter_mz_charge['matched_theo_spectrum'].tolist()))\n",
    "appended_Xcorr_unID = pd.DataFrame()\n",
    "\n",
    "for i in unID_match_index: # Split unassigned dataframe by same matched spectrum index\n",
    "        \n",
    "    # Spectrum binning of unassigned spectra\n",
    "    df_unID_chunk     = df_unID_scan_filter_mz_charge[df_unID_scan_filter_mz_charge['matched_theo_spectrum'] == i]\n",
    "    binned_unID_array = np.vstack(df_unID_chunk[['m/z array', 'intensity array']].apply(lambda x: bin_spec(x['m/z array'], x['intensity array']), axis = 1))\n",
    "    \n",
    "    # Square root transformation & base peak normalization of unassigned spectra\n",
    "    binned_unID_array_sqrt_norm = np.sqrt(binned_unID_array)/np.nanmax(np.sqrt(binned_unID_array), axis = 1)[:,None] \n",
    "    \n",
    "    # Spectrum binning of theoretical spectra\n",
    "    df_pep_mz_filter_temp  = df_pep_mz_filter[df_pep_mz_filter['matched_theo_spectrum'] == i].reset_index(drop = True)\n",
    "    binned_pep_array       = np.vstack(df_pep_mz_filter_temp.apply(lambda x: bin_theo_spec(x['m/z array']), axis = 1))\n",
    "    \n",
    "    # Square root transformation & base peak normalization of theoretical spectra\n",
    "    binned_pep_array_sqrt_norm      = np.sqrt(binned_pep_array)/np.nanmax(np.sqrt(binned_pep_array), axis = 1)[:,None]\n",
    "    binned_pep_array_sqrt_norm_tile = np.tile(binned_pep_array_sqrt_norm, \n",
    "                                              (binned_unID_array_sqrt_norm.shape[0], 1)) # Reshape to unassigned array shape\n",
    "    \n",
    "    # Drop all NaN-only columns common to both unassigned & theoretical spectra\n",
    "    arr_concat                      = np.concatenate([binned_unID_array_sqrt_norm, binned_pep_array_sqrt_norm_tile], axis = 0)\n",
    "    arr_concat_filter               = arr_concat[:,~np.all(np.isnan(arr_concat), axis = 0)]\n",
    "    arr_concat_filter[np.isnan(arr_concat_filter)] = 0\n",
    "    binned_unID_array_sqrt_norm     = arr_concat_filter[0:binned_unID_array_sqrt_norm.shape[0],:]\n",
    "    binned_pep_array_sqrt_norm_tile = arr_concat_filter[binned_unID_array_sqrt_norm.shape[0]:,:]\n",
    "    \n",
    "    # Sum all intensities for m/z shifts\n",
    "    unID_array = np.zeros(shape = binned_unID_array_sqrt_norm.shape)\n",
    "    \n",
    "    for j in range(-75, 76): \n",
    "        if j != 0:\n",
    "            if j < 0:\n",
    "                binned_unID_array_sqrt_norm_shift          = np.roll(binned_unID_array_sqrt_norm, j, axis = 1)\n",
    "                binned_unID_array_sqrt_norm_shift[:,-j:]   = 0\n",
    "                unID_array += binned_unID_array_sqrt_norm_shift\n",
    "            elif j > 0:\n",
    "                binned_unID_array_sqrt_norm_shift          = np.roll(binned_unID_array_sqrt_norm, j, axis = 1)\n",
    "                binned_unID_array_sqrt_norm_shift[:,0:0+j] = 0\n",
    "                unID_array += binned_unID_array_sqrt_norm_shift\n",
    "    \n",
    "    # Calculate Xcorr score\n",
    "    Xcorr_avg           = np.sum(binned_pep_array_sqrt_norm_tile*unID_array, axis = 1)/(2*75)\n",
    "    Xcorr_score         = np.sum(binned_pep_array_sqrt_norm_tile*binned_unID_array_sqrt_norm, axis = 1) - Xcorr_avg\n",
    "    appended_Xcorr_unID = pd.concat([appended_Xcorr_unID, pd.DataFrame(Xcorr_score)], axis = 0)\n",
    "    print('Unassigned Xcorr score calculation: %s/%s chunks processed' %(unID_match_index.index(i), len(unID_match_index)), end=\"\\r\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Xcorr column to unassigned dataframe\n",
    "appended_Xcorr_unID = appended_Xcorr_unID.reset_index(drop = True)\n",
    "df_unID_scan_filter_mz_charge['Xcorr'] = appended_Xcorr_unID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Groupby unassigned scan title\n",
    "info_col      = ['unID_Title', 'exp_Precursor', 'Charge']\n",
    "df_unID_info  = df_unID_scan_filter_mz_charge[info_col].groupby('unID_Title', as_index = False).agg(lambda x: list(set(list(x)))[0])\n",
    "spec_col      = ['unID_Title', 'm/z array', 'intensity array', 'matched_theo_spectrum']\n",
    "df_unID_spec  = df_unID_scan_filter_mz_charge[spec_col].groupby('unID_Title', as_index = False).agg(list)\n",
    "df_unID_Xcorr = df_unID_scan_filter_mz_charge[['unID_Title', 'Xcorr']].groupby('unID_Title', as_index = False).agg(list)\n",
    "df_unID_group = df_unID_info.merge(df_unID_spec, on = 'unID_Title').merge(df_unID_Xcorr, on = 'unID_Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the highest Xcorr for each unassigned spectrum\n",
    "df_unID_group['Best_Xcorr'] = df_unID_group['Xcorr'].apply(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the mathced theoretical spectrum index with the highest Xcorr score\n",
    "df_unID_group['Best_matched_theo_spectrum'] = df_unID_group[['matched_theo_spectrum', 'Xcorr']].apply(lambda x: \n",
    "                                                        x['matched_theo_spectrum'][x['Xcorr'].index(max(x['Xcorr']))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mathced theoretical spectrum m/z array with the highest Xcorr score\n",
    "df_unID_group['m/z array'] = df_unID_group[['m/z array', 'Xcorr']].apply(lambda x: \n",
    "                                                                   x['m/z array'][x['Xcorr'].index(max(x['Xcorr']))], \n",
    "                                                                   axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mathced theoretical spectrum intensity array with the highest Xcorr score\n",
    "df_unID_group['intensity array'] = df_unID_group[['intensity array', 'Xcorr']].apply(lambda x: \n",
    "                                                                               x['intensity array'][x['Xcorr'].index(max(x['Xcorr']))], \n",
    "                                                                               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort experimental dataframe according to theoretical spectrum indices\n",
    "df_unID_group = df_unID_group.sort_values('Best_matched_theo_spectrum', ascending = True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## m/z dataframe\n",
    "# Create a new theoretical m/z dataframe\n",
    "df_pep_mz_info  = df_pep_mz_filter[['Peptide', 'mod_Peptide', 'Pep_length', 'Cit_Count']]\n",
    "df_pep_mz_sub   = df_pep_mz_info.join(df_pep_mz_filter[['matched_theo_spectrum', 'm/z array']])\n",
    "df_pep_mz_match = pd.merge(df_pep_mz_sub, df_unID_group['Best_matched_theo_spectrum'], \n",
    "                           left_on = ['matched_theo_spectrum'], right_on = ['Best_matched_theo_spectrum'], how = 'right')\n",
    "df_pep_mz_match = df_pep_mz_match.sort_values('Best_matched_theo_spectrum', ascending = True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Annotation dataframe\n",
    "# Expand theoretical annotation dataframe\n",
    "df_pep_label_filter['label array'] = df_pep_label_filter.filter(like='mz').values.tolist()\n",
    "df_pep_label_filter['label array'] = df_pep_label_filter['label array'].apply(lambda x: \n",
    "                                                                              [label for label in x if pd.notnull(label)])\n",
    "\n",
    "# Create a new theoretical annotation dataframe\n",
    "df_pep_label_info  = df_pep_label_filter[['Peptide', 'mod_Peptide', 'Pep_length', 'Cit_Count']]\n",
    "df_pep_label_sub   = df_pep_label_info.join(df_pep_label_filter[['matched_theo_spectrum', 'label array']])\n",
    "df_pep_label_match = pd.merge(df_pep_label_sub, df_unID_group['Best_matched_theo_spectrum'], \n",
    "                              left_on = ['matched_theo_spectrum'], right_on = ['Best_matched_theo_spectrum'], how = 'right')\n",
    "df_pep_label_match = df_pep_label_match.sort_values('Best_matched_theo_spectrum', ascending = True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Match experimental with theoretical peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column of mz-intensity pairs\n",
    "df_unID_group['mz_intensity'] = df_unID_group[['m/z array', 'intensity array']].apply(lambda x: \n",
    "                                                                                    [list(t) for t in zip(x['m/z array'], \n",
    "                                                                                                          x['intensity array'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental spectrum\n",
    "df_exp_temp  = df_unID_group.copy()\n",
    "df_exp_temp2 = pd.DataFrame(df_exp_temp['mz_intensity'].values.tolist())\n",
    "df_exp_temp2.fillna(value = np.nan, inplace = True)\n",
    "df_exp_mz    = df_exp_temp['m/z array'].copy()\n",
    "\n",
    "# Theoretical spectrum\n",
    "df_theo_mz    = pd.DataFrame(df_pep_mz_match['m/z array'].values.tolist()).copy() # Theoretical ion m/z\n",
    "df_theo_label = pd.DataFrame(df_pep_label_match['label array'].values.tolist()).copy() # Theoretical ion annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each Experimental spectrum, compare experimental vs. theoretical spectrum and retain only matching ions\n",
    "appended_mz    = []\n",
    "appended_label = []\n",
    "appended_order = []\n",
    "\n",
    "for r in range(len(df_exp_mz)):\n",
    "    # Get non-NaN peaks only\n",
    "    exp_array  = np.array(df_exp_mz[r]) # Experimental peaks\n",
    "    exp_array  = exp_array[~np.isnan(exp_array)] \n",
    "    theo_array = np.array(df_theo_mz.loc[r]) # Theoretical peaks\n",
    "    theo_array = theo_array[~np.isnan(theo_array)]\n",
    "    \n",
    "    # Initial m/z match using nominal m/z\n",
    "    exp_array_int      = exp_array.astype(int)  # Get nominal experimental m/z\n",
    "    theo_array_int     = theo_array.astype(int) # Get nominal theoretical m/z\n",
    "    exp_array_overlap  = np.in1d(exp_array_int, theo_array_int) * exp_array # Check only overlapping nominal m/z\n",
    "    exp_array          = exp_array_overlap[exp_array_overlap > 0] # Retain only overlapping experimental m/z\n",
    "    theo_array_overlap = np.in1d(theo_array_int, exp_array_int) * theo_array # Check only overlapping nominal m/z\n",
    "    theo_array         = theo_array_overlap[theo_array_overlap > 0] # Retain only overlapping theoretical m/z\n",
    "    exp_order          = (exp_array_overlap > 0).astype(int) # Keep original array order\n",
    "    appended_order.append(exp_order)\n",
    "    \n",
    "    # Final m/z match within a predefined m/z tolerance\n",
    "    array_exp_mz  = np.tile(exp_array, (theo_array.shape[0], 1)) # Experimental peak array\n",
    "    array_theo_mz = np.transpose(np.tile(theo_array, (exp_array.shape[0], 1))) # Theoretical peak array\n",
    "    array_eCheck  = abs(array_theo_mz - array_exp_mz) < (array_theo_mz*ms2_ppm * 1e-6) \n",
    "    array_match   = 1*(array_eCheck.sum(axis = 0) > 0)\n",
    "    appended_mz.append(array_match)\n",
    "    \n",
    "    # Get annotation for the retained experimental peaks\n",
    "    exp_mz          = np.sum((array_exp_mz*array_eCheck), axis = 1)\n",
    "    theo_label      = np.array(df_theo_label.loc[r].dropna())\n",
    "    theo_ex_overlap = (theo_label * (theo_array_overlap > 0).astype(bool))\n",
    "    theo_label      = np.array([x for x in theo_ex_overlap if x])\n",
    "    \n",
    "    # Merge peak m/z and annotation\n",
    "    mz_label_pair = pd.DataFrame(np.vstack((exp_mz, theo_label))).T\n",
    "    mz_label_pair.columns = [\"exp_mz\", \"label\"]\n",
    "    mz_label_pair['exp_mz'] = mz_label_pair['exp_mz'].astype(float)\n",
    "    mz_label_pair.loc[mz_label_pair['exp_mz'] == 0, 'label'] = np.nan\n",
    "    mz_label_pair_group = mz_label_pair.groupby('exp_mz', as_index = False)['label'].agg({'labels':(lambda x: list(set(x)))})\n",
    "    mz_label_pair_group = mz_label_pair_group[mz_label_pair_group['exp_mz'] != 0]\n",
    "    appended_label.append(np.array(mz_label_pair_group['labels']))\n",
    "    print(str(r + 1) + str('/%s spectra processed') %(len(df_exp_mz)), end = \"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retain only nominal m/z-matched experimental peaks\n",
    "all_data_order     = (pd.DataFrame(appended_order) > 0).astype(int)\n",
    "df_exp_temp2_order = (df_exp_temp2*all_data_order).applymap(lambda x: np.nan if x == [] else x) \n",
    "df_exp_temp2_order = df_exp_temp2_order.apply(lambda row: pd.Series(row.dropna().values), axis = 1)\n",
    "\n",
    "# Retain only m/z matched experimental peaks\n",
    "all_data_mz = (pd.DataFrame(appended_mz) > 0).astype(int)\n",
    "df_obs      = pd.DataFrame(df_exp_temp2_order.values*all_data_mz.values, \n",
    "                      columns = all_data_mz.columns, index = all_data_mz.index)\n",
    "df_obs      = df_obs.applymap(lambda x: np.nan if x == [] else x)\n",
    "df_obs      = df_obs.apply(lambda row: pd.Series(row.dropna().values), axis = 1)\n",
    "\n",
    "# Merge m/z-intensity-annotation\n",
    "all_data_label = pd.DataFrame([df for df in appended_label])\n",
    "all_data_label = all_data_label.reset_index(drop = True)\n",
    "all_data_label.columns = range(all_data_label.shape[1])\n",
    "df_mz_label    = (df_obs + all_data_label).dropna(how = 'all', axis = 1)\n",
    "df_mz_label.columns = ['peak_%s' % (i+1) for i in range(len(df_mz_label.columns))] # Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Append peptide info columns\n",
    "df_mz_label = df_exp_temp[['unID_Title', 'exp_Precursor', 'Charge']].join(df_pep_mz_match[['Peptide', 'mod_Peptide', \n",
    "                                                                            'Pep_length', 'Cit_Count']]).join(df_mz_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Cit diagnostic ion analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new dataframe\n",
    "df_mz_label_uniq = df_mz_label.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to filter out secondary ions w/o primary ions (for precursor & sequence ion only)\n",
    "def Secondary_filter(Primary_ion_list, Secondary_ion_list):\n",
    "    # Get secondary ion of precursor & sequence ion\n",
    "    Secondary_ion_pri  = [re.sub(r'[0-9]+', '', i.split('-')[0]) for i in Secondary_ion_list]\n",
    "    Secondary_ion_precur_seq = [a*b for a, b in zip([True if ion in ['Precursor', 'y', 'b', 'a', 'z', 'c'] else False \n",
    "                                                     for ion in Secondary_ion_pri], Secondary_ion_list)]\n",
    "    Secondary_ion_precur_seq = [ion for ion in Secondary_ion_precur_seq if len(ion) > 0]\n",
    "    \n",
    "    Secondary_ion_list_filtered = []\n",
    "    for sec in Secondary_ion_list:\n",
    "        if sec in Secondary_ion_precur_seq:\n",
    "            if sec.split('-')[0] in Primary_ion_list:\n",
    "                Secondary_ion_list_filtered.append(sec)\n",
    "        else:\n",
    "            Secondary_ion_list_filtered.append(sec)\n",
    "    \n",
    "    return Secondary_ion_list_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter out secondary ions without primary ions (precursor & sequence ion only)\n",
    "label = df_mz_label_uniq.filter(like = 'peak').applymap(lambda x: x[2:] if isinstance(x, list) else np.nan)\n",
    "appended_list = []\n",
    "\n",
    "for r in range(len(label)):\n",
    "    list_temp = label.loc[r, :].values.tolist()\n",
    "    list_temp = [x for x in list_temp if isinstance(x, list)]\n",
    "    list_temp = [item for sublist in list_temp for item in sublist]\n",
    "    appended_list.append(list_temp)\n",
    "    \n",
    "Primary_ion   = pd.Series(appended_list).apply(lambda x: [ion for ion in x if '-' not in ion])\n",
    "Secondary_ion = pd.Series(appended_list).apply(lambda x: [ion for ion in x if '-' in ion])\n",
    "\n",
    "# Append a total annotation column\n",
    "Total_ion = Primary_ion + pd.DataFrame([Primary_ion, Secondary_ion]).T.apply(lambda x: Secondary_filter(x[0], x[1]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove annotations not in the filtered total annotation list\n",
    "def Annot_filter(peaks, Total_label):\n",
    "    \n",
    "    peaks = [peak if (isinstance(peak, list) and len(set(peak[2:]).intersection(Total_label)) > 0) else np.nan \n",
    "             for peak in peaks]\n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtered peak annotation\n",
    "all_peaks = df_mz_label_uniq.filter(like = 'peak').applymap(lambda x: x if isinstance(x, list) else np.nan)\n",
    "appended_list = []\n",
    "\n",
    "for r in range(len(all_peaks)):\n",
    "    list_temp = all_peaks.loc[r, :].values.tolist()\n",
    "    list_temp = [x if isinstance(x, list) else np.nan for x in list_temp]\n",
    "    appended_list.append(list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update original dataframe\n",
    "df_mz_label_uniq_info = df_mz_label_uniq.loc[:,~df_mz_label_uniq.columns.str.contains('peak')]\n",
    "Ions                  = pd.DataFrame([appended_list, Total_ion]).T.apply(lambda x: Annot_filter(x[0], x[1]), axis = 1)\n",
    "df_mz_label_uniq      = df_mz_label_uniq_info.join(pd.DataFrame(Ions.tolist(),\n",
    "                                                           columns = df_mz_label_uniq.filter(like = 'peak').columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retain only unique 43 NL\n",
    "def uniq_43(labels):\n",
    "    # If there is only one 43 NL annotation, retain it\n",
    "    if len(labels) == 1:\n",
    "        if '43' in labels[0]:\n",
    "            return labels\n",
    "        else:\n",
    "            return np.nan\n",
    "    \n",
    "    # In case of multiple annotations\n",
    "    else:\n",
    "        # Check whether there is at least one 43 NL annotation\n",
    "        labels_43 = [('43' in label) for label in labels]\n",
    "        \n",
    "        # If there is no 43 NL annotation, return NaN\n",
    "        if Counter(labels_43)[True] == 0:            \n",
    "            return np.nan\n",
    "        \n",
    "        # If there is at least one 43 NL annotation\n",
    "        else:\n",
    "            # If all labels are 43 NL annotations, retain all\n",
    "            if Counter(labels_43)[True] == len(labels):\n",
    "                Precur_43 = [label for label in labels if 'Precur' in label]\n",
    "                seq_43    = [label for label in labels if \n",
    "                             any(['y' in label, 'b' in label, 'a' in label]) == True and \n",
    "                             len(re.sub(r'[0-9]+', '', label.split('-')[0])) == 1]\n",
    "                INT_43    = list(set(labels) - set(Precur_43 + seq_43))\n",
    "                if len(Precur_43) > 0: # If there is precursor 43 NL, return it\n",
    "                    return Precur_43\n",
    "                elif len(seq_43) > 0: # If there is no precursor but sequence 43 NL, return it\n",
    "                    return seq_43\n",
    "                else: # If there is no precursor & sequence but INT 43 NL, return it\n",
    "                    return INT_43\n",
    "            # If there is at least one non-43 NL annotation, \n",
    "            else:\n",
    "                labels_43_non = [label for label in labels if labels_43[labels.index(label)] == False]\n",
    "                # If non-43 NL is of precursor or sequence ion type, remove 43 NL\n",
    "                if len([label for label in labels_43_non if \n",
    "                        any(['Precur' in label, 'y' in label, 'b' in label, 'a' in label]) == True and \n",
    "                        len(re.sub(r'[0-9]+', '', label.split('-')[0])) == 1]) > 0:\n",
    "                    return np.nan\n",
    "                # If non-43 NL is an immonium ion, remove 43 NL\n",
    "                elif len([label for label in labels_43_non if 'IM(' in label]) > 0:\n",
    "                    return np.nan\n",
    "                else: # Otherwise, retain 43 NL\n",
    "                    return list(set(labels) - set(labels_43_non))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retain only unique INT\n",
    "def uniq_INT(labels):\n",
    "    \n",
    "    INT = [label for label in labels if all(['r' in label, 'IM(' not in label, 'Precur' not in label, \n",
    "                                             len(label.split('-')[0]) in range(2,4)]) == True]\n",
    "    non_INT = list(set(labels) - set(INT))\n",
    "    # If there is no di/tripeptide, return NaN\n",
    "    if len(INT) == 0:\n",
    "        return np.nan\n",
    "    else:    \n",
    "        # If there is no non-INT annotation, retain INT annotation\n",
    "        if len(non_INT) == 0:\n",
    "            return INT\n",
    "        else: # If there is at least one non-INT annotation, return NaN\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retain unique 43 NL and INT\n",
    "unique_NL  = pd.Series(df_mz_label_uniq.filter(like = 'peak').applymap(lambda x: \n",
    "                                                                       uniq_43(x[2:])  if isinstance(x, list) else np.nan).values.tolist()).apply(lambda x: [label for label in x if isinstance(label, list)])\n",
    "unique_INT = pd.Series(df_mz_label_uniq.filter(like = 'peak').applymap(lambda x: \n",
    "                                                                       uniq_INT(x[2:]) if isinstance(x, list) else np.nan).values.tolist()).apply(lambda x: [label for label in x if isinstance(label, list)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unique Cit DI annotations\n",
    "# Get unique 43 NL annotations\n",
    "Total_NL_label = unique_NL.apply(lambda x: [label for sublist in x for label in sublist])\n",
    "df_mz_label_uniq['Total_NL_label'] = Total_NL_label.apply(lambda x: ','.join(x))\n",
    "df_mz_label_uniq['precNL_label']   = Total_NL_label.apply(lambda x: ','.join([label for label in x if 'Precur' in label]))\n",
    "df_mz_label_uniq['seqNL_label']    = Total_NL_label.apply(lambda x: ','.join([label for label in x if \n",
    "                                                                              any(['y' in label, 'b' in label, 'a' in label]) == True and \n",
    "                                                                              len(re.sub(r'[0-9]+', '', label.split('-')[0])) == 1]))\n",
    "df_mz_label_uniq['intNL_label']    = Total_NL_label.apply(lambda x: ','.join([label for label in x if \n",
    "                                                                              all(['r' in label, 'Precur' not in label]) == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique INT annotations\n",
    "Total_INT_label = unique_INT.apply(lambda x: [label for sublist in x for label in sublist])\n",
    "df_mz_label_uniq['Total_INT_label']  = Total_INT_label.apply(lambda x: ','.join(x))\n",
    "df_mz_label_uniq['Dipeptide_label']  = Total_INT_label.apply(lambda x: ','.join([label for label in x if \n",
    "                                                                                 len(label.split('-')[0]) == 2]))\n",
    "df_mz_label_uniq['Tripeptide_label'] = Total_INT_label.apply(lambda x: ','.join([label for label in x if \n",
    "                                                                                 len(label.split('-')[0]) == 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## IM(Cit)-NH3 filtering using intensity ratio of IM(R)-NH3/IM(Cit)-NH3\n",
    "# Get IM(Cit)-NH3 intensity\n",
    "IMCit_NH3 = pd.Series(df_mz_label_uniq.filter(like = 'peak').applymap(lambda x: x[1] if isinstance(x, list) and \n",
    "                                                                      'IM(r)-NH3' in x[2:] else np.nan).values.tolist())\n",
    "IMCit_NH3 = IMCit_NH3.apply(lambda x: [intensity for intensity in x if pd.notnull(intensity)]).apply(lambda x: x[0] if len(x) > 0 else np.nan)\n",
    "IMCit_NH3_presence = (IMCit_NH3 > 0).astype(int)\n",
    "\n",
    "# Get IM(R)-NH3 intensity\n",
    "IMR_NH3 = pd.Series(df_mz_label_uniq.filter(like = 'peak').applymap(lambda x: x[1] if isinstance(x, list) and \n",
    "                                                                    'IM(R)-NH3' in x[2:] else np.nan).values.tolist())\n",
    "IMR_NH3 = IMR_NH3.apply(lambda x: [intensity for intensity in x if pd.notnull(intensity)]).apply(lambda x: x[0] if len(x) > 0 else np.nan)\n",
    "\n",
    "# Retain only IM(Cit)-NH3 with intensity greater than that of IM(R)-NH3\n",
    "IM_filter = ((IMR_NH3/IMCit_NH3) > 1).astype(int)\n",
    "IMCit_NH3_presence_filtered = IMCit_NH3_presence - (IMCit_NH3_presence*IM_filter)\n",
    "\n",
    "# Get IM(Cit)-NH3 annotation\n",
    "df_mz_label_uniq['IM_NH3_label'] = Total_ion.apply(lambda x: ','.join([label for label in x \n",
    "                                                                       if label == 'IM(r)-NH3']))*IMCit_NH3_presence_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique 43 NL counts\n",
    "df_mz_label_uniq['Total_NL_count'] = df_mz_label_uniq['Total_NL_label'].apply(lambda x: len(x.split(',')) if len(x) > 0 else 0)\n",
    "df_mz_label_uniq['precNL_count']   = df_mz_label_uniq['precNL_label'].apply(lambda x: len(x.split(',')) if len(x) > 0 else 0)\n",
    "df_mz_label_uniq['seqNL_count']    = df_mz_label_uniq['seqNL_label'].apply(lambda x: len(x.split(',')) if len(x) > 0 else 0)\n",
    "df_mz_label_uniq['intNL_count']    = df_mz_label_uniq['intNL_label'].apply(lambda x: len(x.split(',')) if len(x) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique INT counts\n",
    "df_mz_label_uniq['Total_INT_count']  = unique_INT.str.len()\n",
    "df_mz_label_uniq['Dipeptide_count']  = unique_INT.apply(lambda x: [label for label in x if \n",
    "                                                                   len(label[0].split('-')[0]) == 2]).str.len()\n",
    "df_mz_label_uniq['Tripeptide_count'] = unique_INT.apply(lambda x: [label for label in x if \n",
    "                                                                   len(label[0].split('-')[0]) == 3]).str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get IM(Cit)-NH3 counts\n",
    "df_mz_label_uniq['IM_NH3_count'] = df_mz_label_uniq['IM_NH3_label'].apply(lambda x: 1 if len(x) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get intensity coverage (= summed intensity of annotated peaks / total intensity of MS2 peaks)\n",
    "# Summed intensity of annotated peaks\n",
    "appended_list = []\n",
    "\n",
    "for r in range(len(label)):\n",
    "    list_temp             = label.loc[r, :].values.tolist()\n",
    "    list_temp             = [1 if x in Total_ion[r] else 0 for x in list_temp]\n",
    "    appended_list.append(list_temp)\n",
    "    \n",
    "annotated_intensity = df_mz_label_uniq.filter(like='peak').applymap(lambda x: x[1] if \n",
    "                                                                    isinstance(x, list) else np.nan).sum(axis = 1)\n",
    "\n",
    "# Total intensity of MS2 peaks in unID spectrum\n",
    "total_MS2_intensity = df_unID_group['intensity array'].apply(sum)\n",
    "\n",
    "# Get intensity coverage\n",
    "df_mz_label_uniq['Intensity_coverage'] = annotated_intensity / total_MS2_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out spectra with low intensity coverage\n",
    "Final_result = df_mz_label_uniq[[col for col in df_mz_label_uniq.columns if 'peak' not in col]]\n",
    "Final_result_filter = Final_result[Final_result['Intensity_coverage'] >= intensity_coverage].reset_index(drop = True).drop(columns = ['Intensity_coverage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluation of Cit PSMs by logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate Cit probability using the EN model developed in the paper\n",
    "def EN_model(NL_count, INT_count, IM_NH3_count):\n",
    "    # Regression coefficients\n",
    "    Intercept = -1.9270\n",
    "    NL_coeff  = 0.9759\n",
    "    INT_coeff = 0.6519\n",
    "    IM_coeff  = 2.7804\n",
    "    \n",
    "    # Logit function\n",
    "    logit = Intercept + NL_coeff*NL_count + INT_coeff*INT_count + IM_coeff*IM_NH3_count\n",
    "    prob  = np.exp(logit)/(np.exp(logit) + 1)\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the EN model\n",
    "Cit_prob = Final_result_filter[['Total_NL_count', 'Total_INT_count', 'IM_NH3_count']].apply(lambda x: \n",
    "                                                                                            EN_model(x['Total_NL_count'], \n",
    "                                                                                                     x['Total_INT_count'], \n",
    "                                                                                                     x['IM_NH3_count']), \n",
    "                                                                                            axis = 1)\n",
    "Final_result_filter = Final_result_filter.assign(Cit_probability = Cit_prob) # Citrullination status probability\n",
    "Final_result_filter = Final_result_filter.assign(Cit_prediction = np.where(Cit_prob >= 0.5, 1, 0)) # Citrullination status classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result\n",
    "Final_result_filter.to_csv(\"False_negative_prediction.csv\") # As csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
